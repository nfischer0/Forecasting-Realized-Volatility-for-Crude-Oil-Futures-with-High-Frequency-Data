{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.special import gamma\n",
    "from math import ceil, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = pd.read_csv('prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soren\\AppData\\Local\\Temp\\ipykernel_24756\\1448499391.py:20: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  intraday_returns = data.groupby(pd.Grouper(freq=\"1d\")).apply(lambda x: np.log(x / x.shift(1))).dropna()\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from https://github.com/BayerSe/RealizedQuantities/blob/master/main.py#L17\n",
    "\n",
    "def realized_quantity(fun):\n",
    "    \"\"\"Applies the function 'fun' to each day separately\"\"\"\n",
    "    return intraday_returns.groupby(pd.Grouper(freq=\"1d\")).apply(fun).loc[index]\n",
    "\n",
    "# Settings\n",
    "trading_seconds = 300\n",
    "avg_sampling_frequency = 300\n",
    "original_sampling_frequency = 300  # From the process_data.py file\n",
    "\n",
    "# I don't know what this ratio should be so I'll just set it to one for now\n",
    "M = trading_seconds / original_sampling_frequency\n",
    "\n",
    "# Load data and store the intraday returns\n",
    "data = pd.read_csv(\"prices.csv\")\n",
    "data['Local time'] = pd.to_datetime(data[\"Local time\"],format='%Y-%m-%d %H:%M:%S')\n",
    "data = data.set_index(\"Local time\", drop=False)\n",
    "data = data[[\"Close_fut\"]]\n",
    "intraday_returns = data.groupby(pd.Grouper(freq=\"1d\")).apply(lambda x: np.log(x / x.shift(1))).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of all days\n",
    "index = data.groupby(pd.Grouper(freq=\"1d\")).first().dropna().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants\n",
    "mu_1 = np.sqrt((2 / np.pi))\n",
    "mu_43 = 2 ** (2 / 3) * gamma(7 / 6) * gamma(1 / 2) ** (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First and last price of each day\n",
    "prices_open = data.resample('D').first().loc[index]\n",
    "prices_close = data.resample('D').last().loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return (close-to-close and open-to-close)\n",
    "r_cc = np.log(prices_close / prices_close.shift(1))\n",
    "r_oc = np.log(prices_close / prices_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realized Variance (Andersen and Bollerslev, 1998)\n",
    "rv = realized_quantity(lambda x: (x ** 2).sum())\n",
    "\n",
    "# Realized absolute variation (Forsberg and Ghysels, 2007)\n",
    "rav = mu_1 ** (-1) * M ** (-.5) * realized_quantity(lambda x: x.abs().sum())\n",
    "\n",
    "# Realized bipower variation (Barndorff-Nielsen and Shephard; 2004, 2006)\n",
    "bv = mu_1 ** (-2) * realized_quantity(lambda x: (x.abs() * x.shift(1).abs()).sum())\n",
    "\n",
    "# Standardized tri-power quarticity (see e.g. Forsberg & Ghysels, 2007)\n",
    "tq = M * mu_43 ** (-3) * realized_quantity(\n",
    "    lambda x: (x.abs() ** (4 / 3) * x.shift(1).abs() ** (4 / 3) * x.shift(2).abs() ** (4 / 3)).sum())\n",
    "\n",
    "# Jump test by Huang and Tauchen (2005)\n",
    "j = (np.log(rv+0.00000001) - np.log(bv+0.00000001)) / \\\n",
    "    ((mu_1 ** -4 + 2 * mu_1 ** -2 - 5) / (M * tq * bv ** -2)) ** 0.5\n",
    "jump = j.abs() >= stats.norm.ppf(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate continuous and discontinuous parts of the quadratic variation\n",
    "iv = pd.Series(0, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't employ these since no jumps were detected\n",
    "#iv[jump[\"Close_fut\"].values.squeeze()] = bv[jump[\"Close_fut\"].values.squeeze()] ** 0.5\n",
    "#iv[not jump[\"Close_fut\"].values] = rv[not jump[\"Close_fut\"].values] ** 0.5\n",
    "\n",
    "# jv = pd.Series(0, index=index)\n",
    "# jv[jump] = rv[jump] ** 0.5 - bv[jump] ** 0.5\n",
    "# jv[jv < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realized Semivariance (Barndorff-Nielsen, Kinnebrock and Shephard, 2010)\n",
    "rv_m = realized_quantity(lambda x: (x ** 2 * (x < 0)).sum())\n",
    "rv_p = realized_quantity(lambda x: (x ** 2 * (x > 0)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signed jump variation (Patton and Sheppard, 2015)\n",
    "sjv = rv_p - rv_m\n",
    "sjv_p = sjv * (sjv > 0)\n",
    "sjv_m = sjv * (sjv < 0)\n",
    "\n",
    "# Realized Skewness and Kurtosis  (see, e.g. Amaya, Christoffersen, Jacobs and Vasquez, 2015)\n",
    "rm3 = realized_quantity(lambda x: (x ** 3).sum())\n",
    "rm4 = realized_quantity(lambda x: (x ** 4).sum())\n",
    "rs = np.sqrt(M) * rm3 / rv ** (3 / 2)\n",
    "rk = M * rm4 / rv ** 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export all the features we made to a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "out = pd.concat([r_cc, r_oc, rav, rv ** .5, bv ** .5, rv_m ** 0.5, rv_p ** 0.5,\n",
    "                    sjv, sjv_p, sjv_m, rs, rk], axis=1)\n",
    "out.columns = ['r_cc', 'r_oc', 'rav', 'rvol', 'bvol', 'rvol_m', 'rvol_p',\n",
    "                 'sjv', 'sjv_p', 'sjv_m', 'rs', 'rk']\n",
    "out.to_csv('realized_quantities.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so let's try to make some more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://gist.github.com/linuskohl/690da335a34ebf1cfc5ab27973e16ee5\n",
    "def movmean(v, kb, kf):\n",
    "    \"\"\"\n",
    "    Computes the mean with a window of length kb+kf+1 that includes the element \n",
    "    in the current position, kb elements backward, and kf elements forward.\n",
    "    Nonexisting elements at the edges get substituted with NaN.\n",
    "    Args:\n",
    "        v (list(float)): List of values.\n",
    "        kb (int): Number of elements to include before current position\n",
    "        kf (int): Number of elements to include after current position\n",
    "    Returns:\n",
    "        list(float): List of the same size as v containing the mean values\n",
    "    \"\"\"\n",
    "    m = len(v) * [np.nan]\n",
    "    for i in range(kb, len(v)-kf):\n",
    "        m[i] = np.mean(v[i-kb:i+kf+1])\n",
    "    return m\n",
    "\n",
    "def LeeMykland(df, sampling, significance_level=0.01):\n",
    "    \"\"\"\n",
    "    \"Jumps in Equilibrium Prices and Market Microstructure Noise\"\n",
    "    - by Suzanne S. Lee and Per A. Mykland\n",
    "    \n",
    "    \"https://galton.uchicago.edu/~mykland/paperlinks/LeeMykland-2535.pdf\"\n",
    "    \n",
    "    Args:\n",
    "        S (list(float)): An array containing prices, where each entry \n",
    "                         corresponds to the price sampled every 'sampling' minutes.\n",
    "        sampling (int): Minutes between entries in S\n",
    "        significance_level (float): Defaults to 1% (0.001)\n",
    "        \n",
    "    Returns:\n",
    "        A pandas dataframe containing a row covering the interval \n",
    "        [t_i, t_i+sampling] containing the following values:\n",
    "        J:   Binary value is jump with direction (sign)\n",
    "        L:   L statistics\n",
    "        T:   Test statistics\n",
    "        sig: Volatility estimate\n",
    "    \"\"\"\n",
    "    #tm = 252*24*60 # Trading minutes\n",
    "    # Sincere we are only calculating within each day\n",
    "    tm = 107 * 5\n",
    "    S = df['Close_fut'].values\n",
    "    k   = ceil(sqrt(tm/sampling))\n",
    "    r = np.append(np.nan, np.diff(np.log(S)))\n",
    "    bpv = np.multiply(np.absolute(r[:]), np.absolute(np.append(np.nan, r[:-1])))\n",
    "    bpv = np.append(np.nan, bpv[0:-1]).reshape(-1,1) # Realized bipower variation\n",
    "    sig = np.sqrt(movmean(bpv, k-3, 0)) # Volatility estimate\n",
    "    L   = r/sig\n",
    "    n   = np.size(S) # Length of S\n",
    "    c   = (2/np.pi)**0.5\n",
    "    Sn  = c*(2*np.log(n))**0.5\n",
    "    Cn  = (2*np.log(n))**0.5/c - np.log(np.pi*np.log(n))/(2*c*(2*np.log(n))**0.5)\n",
    "    beta_star   = -np.log(-np.log(1-significance_level)) # Jump threshold\n",
    "    T   = (abs(L)-Cn)*Sn\n",
    "    J   = (T > beta_star).astype(float)\n",
    "    J   = J*np.sign(r) # Add direction\n",
    "    # First k rows are NaN involved in bipower variation estimation are set to NaN.\n",
    "    J[0:k] = np.nan\n",
    "    # Build and retunr result dataframe\n",
    "    return pd.DataFrame({'L': L,'sig': sig, 'T': T,'J':J})\n",
    "\n",
    "def curried_Lee(x):\n",
    "    return LeeMykland(x, sampling=5)\n",
    "\n",
    "# a = realized_quantity(curried_Lee)\n",
    "# a[a[['L', 'sig', 'T',\"J\"]].notnull().all(1)]\n",
    "\n",
    "# not using the above approach for now since it gives mostly NaNs\n",
    "# its very likely I'm doing something wrong and it could actually work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Causality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "960d2775473cb3d065e28c47b6bd81ca92f30da6618703e462b5ce909118ad7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
